{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "higher-junction",
   "metadata": {},
   "source": [
    "# Risk Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import statsmodels as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "from scipy.stats import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-geneva",
   "metadata": {},
   "source": [
    "Distribuciones de scipy y su documentación:\n",
    "https://docs.scipy.org/doc/scipy/reference/stats.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-conference",
   "metadata": {},
   "source": [
    "Distribuciones de numpy y su documentación:\n",
    "https://numpy.org/doc/1.16/reference/routines.random.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-adams",
   "metadata": {},
   "source": [
    "## Ajustar mejor distribución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import volatilities\n",
    "vols = pd.read_excel(\"vols.xlsx\")\n",
    "vols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee = vols[\"Coffee\"]\n",
    "trm = vols[\"COPUSD\"]\n",
    "coffee_cop = vols[\"CoffeeCOP\"]\n",
    "\n",
    "coffee.dropna(inplace = True)\n",
    "trm.dropna(inplace = True)\n",
    "coffee_cop.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from fitter import Fitter\n",
    "f1 = Fitter(coffee)\n",
    "f1.fit()\n",
    "# may take some time since by default, all distributions are tried\n",
    "# but you call manually provide a smaller set of distributions\n",
    "f1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "f2 = Fitter(trm)\n",
    "f2.fit()\n",
    "# may take some time since by default, all distributions are tried\n",
    "# but you call manually provide a smaller set of distributions\n",
    "f2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "f3 = Fitter(coffee_cop)\n",
    "f3.fit()\n",
    "# may take some time since by default, all distributions are tried\n",
    "# but you call manually provide a smaller set of distributions\n",
    "f3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-clark",
   "metadata": {},
   "source": [
    "Obtener parametros para las mejores distribuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Parms of coffee\",f1.fitted_param['dgamma'])\n",
    "print(\"Parms of trm\", f2.fitted_param['fatiguelife'])\n",
    "print(\"Parms of coffee cop\",f3.fitted_param['laplace'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definir inputs:\n",
    "n = 5000\n",
    "pct_cobertura = 0.3\n",
    "\n",
    "#IBR\n",
    "ibr_min = 0.01\n",
    "ibr_c = 0.035\n",
    "ibr_max = 0.05\n",
    "ibr = np.random.triangular(ibr_min, ibr_c, ibr_max, size=n)\n",
    "\n",
    "#LIBOR\n",
    "lib_min = 0\n",
    "lib_c = 0.029\n",
    "lib_max = 0.038\n",
    "lib = np.random.triangular(lib_min, lib_c, lib_max, size=n)\n",
    "\n",
    "#Vol Café ------Limitar a valores positivos\n",
    "vol_coffee = dgamma.rvs(1.4863778547163755, loc = 0.356, scale = 0.0465, size=n)\n",
    "vol_coffee[vol_coffee < 0.0] = vol_coffee.mean()\n",
    "\n",
    "#Vol Dólar\n",
    "vol_trm = fatiguelife.rvs(0.5202 ,loc = 0.0139, scale = 0.0747, size = n)\n",
    "vol_trm[vol_trm < 0.0] = vol_trm.mean()\n",
    "\n",
    "#vol Cafe cop\n",
    "vol_coffee_cop = laplace.rvs(loc = 0.2350, scale = 0.05825)\n",
    "\n",
    "\n",
    "\n",
    "#precio café\n",
    "#definir distribucion del café\n",
    "\n",
    "#precio dólar\n",
    "#definir distribucion del dolar - hacer browniano geométrico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-recommendation",
   "metadata": {},
   "source": [
    "## Black Scholes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, sqrt, pi, exp\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(S,K,T,r,sigma):\n",
    "    lns0k = log(S/K)\n",
    "    rmas = (r+(sigma**2)/2.0)*T\n",
    "    srt = sigma*sqrt(T)\n",
    "    d1 = (lns0k + rmas) / srt\n",
    "    d2 = d1 - srt\n",
    "    Nd1 = norm.cdf(d1)\n",
    "    Nd2 = norm.cdf(d2)\n",
    "    ert = exp(-T*r)\n",
    "    price = S*Nd1-K*ert*Nd2\n",
    "    return(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-sleeve",
   "metadata": {},
   "source": [
    "## Simulación masiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simular primas café base\n",
    "primas_pct = []\n",
    "\n",
    "ss = -0.02 #Strike vs Spot\n",
    "S = 100 #spot\n",
    "K = S*(1+ss) #strike\n",
    "T = 1 #time in years\n",
    "\n",
    "for i in range(n):\n",
    "    r = lib[i] #free risk interest rate\n",
    "    sigma = vol_coffee[i] #volatility of asset (annualized)\n",
    "    prima = call(S,K,T,r,sigma) # price of option in unites\n",
    "    prima_pct = prima / K #price of option %\n",
    "    primas_pct.append(prima_pct)\n",
    "    \n",
    "sns.histplot(primas_pct, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simular primas trm\n",
    "primas_pct = []\n",
    "\n",
    "for i in range(n):\n",
    "    ss = -0.02 #Strike vs Spot\n",
    "    S = 3500 #spot\n",
    "    K = S*(1+ss) #strike\n",
    "    T = 1 #time in years\n",
    "    r = ibr[i] - lib[i] #free risk interest rate\n",
    "    sigma = vol_trm[i] #volatility of asset (annualized)\n",
    "    prima = call(S,K,T,r,sigma) # price of option in unites\n",
    "    prima_pct = prima / K #price of option %\n",
    "    primas_pct.append(prima_pct)\n",
    "    \n",
    "sns.histplot(primas_pct, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "S = 100 #spot coffee base\n",
    "S2 = 3500 #spot trm base\n",
    "T = 1 #time in years\n",
    "\n",
    "#dist strike vs spot \n",
    "ss_array_coffee = np.random.triangular(-0.5, 0, 0.5, size=n) #Triangular con moda 0 min -50% y max +50%\n",
    "ss_array_trm = np.random.triangular(-0.5, 0, 0.5, size=n) #Triangular con moda 0 min -50% y max +50%\n",
    "\n",
    "#Combinacion de las dos primas\n",
    "primas_pct = []\n",
    "primas_pct2 = []\n",
    "primas_pct_all = []\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    #coffee\n",
    "    ss =  ss_array_coffee[i] #Strike vs Spot\n",
    "    K = S*(1+ss) #strike coffee\n",
    "    r = lib[i] #free risk interest rate\n",
    "    sigma = vol_coffee[i] #volatility of asset (annualized)\n",
    "    prima = call(S,K,T,r,sigma) # price of option in unites\n",
    "    prima_pct = prima / K #price of option %\n",
    "    primas_pct.append(prima_pct)\n",
    "    \n",
    "    #trm\n",
    "    ss2 = ss_array_trm[i]\n",
    "    K2 = S2*(1+ss2)\n",
    "    r2 = ibr[i] - lib[i]\n",
    "    sigma2 = vol_trm[i]\n",
    "    prima2 = call(S2, K2, T, r2, sigma2)\n",
    "    prima_pct2 = prima2 / K2\n",
    "    primas_pct2.append(prima_pct2)\n",
    "    \n",
    "    #combinacion\n",
    "    prima_pct_all = (prima_pct + prima_pct2)*pct_cobertura\n",
    "    primas_pct_all.append(prima_pct_all)\n",
    "    \n",
    "    \n",
    "    \n",
    "sns.histplot(primas_pct_all, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-difficulty",
   "metadata": {},
   "source": [
    "## Simulación de precios futuros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-balloon",
   "metadata": {},
   "source": [
    "### Geometric Brownian Motion GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Definitions\n",
    "\n",
    "# So    :   initial stock price\n",
    "# dt    :   time increment -> a day in our case\n",
    "# T     :   length of the prediction time horizon(how many time points to predict, same unit with dt(days))\n",
    "# N     :   number of time points in the prediction time horizon -> T/dt\n",
    "# t     :   array for time points in the prediction time horizon [1, 2, 3, .. , N]\n",
    "# mu    :   mean of historical daily returns\n",
    "# sigma :   standard deviation of historical daily returns\n",
    "# b     :   array for brownian increments\n",
    "# W     :   array for brownian path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-ceremony",
   "metadata": {},
   "source": [
    "### Simulación Precio Café"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-europe",
   "metadata": {},
   "source": [
    "#### Yahoo Financie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "quandl.ApiConfig.api_key = \"1VS8Ys2-9xQMfabc_KfS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2000-01-01'\n",
    "end_date = '2021-02-28'\n",
    "pred_end_date = '2021-06-30'\n",
    "\n",
    "# We get daily closing prices for Coffee C Futures\n",
    "kc = quandl.get(\"CHRIS/ICE_KC1\", start_date=start_date, \n",
    "                    end_date=end_date).reset_index(drop = False)[['Date', 'Settle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = (kc.loc[1:, 'Settle'] - \\\n",
    "           kc.shift(1).loc[1:, 'Settle']) / \\\n",
    "           kc.shift(1).loc[1:, 'Settle']\n",
    "\n",
    "\n",
    "# Parameter Assignments\n",
    "So = kc.loc[kc.shape[0] - 1, \"Settle\"]\n",
    "dt = 1 # day   # User input\n",
    "n_of_wkdays = pd.date_range(start = pd.to_datetime(end_date, \n",
    "                 format = \"%Y-%m-%d\") + pd.Timedelta('1 days'), \n",
    "                 end = pd.to_datetime(pred_end_date, \n",
    "                 format = \"%Y-%m-%d\")).to_series().map(lambda x: \n",
    "                 1 if x.isoweekday() in range(1,6) else 0).sum()\n",
    "Tb = n_of_wkdays # days  # User input -> follows from pred_end_date\n",
    "N = Tb / dt\n",
    "t = np.arange(1, int(N) + 1)\n",
    "mu = np.mean(returns)\n",
    "sigma = np.std(returns)\n",
    "scen_size = 50 # User input\n",
    "b = {str(scen): np.random.normal(0, 1, int(N)) for scen in range(1, scen_size + 1)}\n",
    "W = {str(scen): b[str(scen)].cumsum() for scen in range(1, scen_size + 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "drift = (mu - 0.5 * sigma**2) * t\n",
    "diffusion = {str(scen): sigma * W[str(scen)] for scen in range(1, scen_size + 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the predictions\n",
    "S_c = np.array([So * np.exp(drift + diffusion[str(scen)]) for scen in range(1, scen_size + 1)]) \n",
    "S_c = np.hstack((np.array([[So] for scen in range(scen_size)]), S_c)) # add So to the beginning series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the simulations\n",
    "plt.figure(figsize = (20,10))\n",
    "for i in range(scen_size):\n",
    "    plt.title(\"Daily Volatility: \" + str(sigma))\n",
    "    plt.plot(pd.date_range(start = kc[\"Date\"].max(), \n",
    "                end = pred_end_date, freq = 'D').map(lambda x:\n",
    "                x if x.isoweekday() in range(1, 6) else np.nan).dropna(), S_c[i, :])\n",
    "    plt.ylabel('Stock Prices, $')\n",
    "    plt.xlabel('Prediction Days')\n",
    "plt.show()\n",
    "\n",
    "# Dataframe format for predictions - first 10 scenarios only\n",
    "Preds_df_coffee = pd.DataFrame(S_c.swapaxes(0, 1)[:, :10]).set_index(\n",
    "           pd.date_range(start = kc[\"Date\"].max(), \n",
    "           end = pred_end_date, freq = 'D').map(lambda x:\n",
    "           x if x.isoweekday() in range(1, 6) else np.nan).dropna()\n",
    "           ).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-auction",
   "metadata": {},
   "source": [
    "### Movimiento Browniano COP / USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import investpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_datei = '01/01/2000'\n",
    "end_datei = '28/02/2021'\n",
    "pred_end_datei = '30/06/2021'\n",
    "\n",
    "\n",
    "df = investpy.get_currency_cross_historical_data(currency_cross='USD/COP',\n",
    "                                                 from_date=start_datei,\n",
    "                                                 to_date=end_datei).reset_index(drop = False)[['Date', 'Close']]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_trm = df[\"Close\"].pct_change().dropna()\n",
    "\n",
    "\n",
    "# Parameter Assignments\n",
    "So_trm = df.loc[df.shape[0] - 1, \"Close\"]\n",
    "dt = 1 # day   # User input\n",
    "n_of_wkdays = pd.date_range(start = pd.to_datetime(end_datei) + pd.Timedelta('1 days'), \n",
    "                 end = pd.to_datetime(pred_end_datei)).to_series().map(lambda x: \n",
    "                 1 if x.isoweekday() in range(1,6) else 0).sum()\n",
    "\n",
    "\n",
    "Tb = n_of_wkdays # days  # User input -> follows from pred_end_date\n",
    "N = Tb / dt\n",
    "t = np.arange(1, int(N) + 1)\n",
    "mu_trm = np.mean(returns_trm)\n",
    "sigma_trm = np.std(returns_trm)\n",
    "scen_size = 50 # User input\n",
    "b = {str(scen): np.random.normal(0, 1, int(N)) for scen in range(1, scen_size + 1)}\n",
    "W = {str(scen): b[str(scen)].cumsum() for scen in range(1, scen_size + 1)}\n",
    "\n",
    "drift_trm = (mu_trm - 0.5 * sigma_trm**2) * t\n",
    "diffusion_trm = {str(scen): sigma_trm * W[str(scen)] for scen in range(1, scen_size + 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the predictions\n",
    "S_trm = np.array([So_trm * np.exp(drift_trm + diffusion_trm[str(scen)]) for scen in range(1, scen_size + 1)]) \n",
    "S_trm = np.hstack((np.array([[So_trm] for scen in range(scen_size)]), S_trm)) # add So to the beginning series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the simulations\n",
    "plt.figure(figsize = (20,10))\n",
    "for i in range(scen_size):\n",
    "    plt.title(\"Daily Volatility: \" + str(sigma_trm))\n",
    "    plt.plot(pd.date_range(start = df[\"Date\"].max(), \n",
    "                end = pred_end_datei, freq = 'D').map(lambda x:\n",
    "                x if x.isoweekday() in range(1, 6) else np.nan).dropna(), S_trm[i, :])\n",
    "    plt.ylabel('Stock Prices, $')\n",
    "    plt.xlabel('Prediction Days')\n",
    "plt.show()\n",
    "\n",
    "# Dataframe format for predictions - first 10 scenarios only\n",
    "Preds_df_trm = pd.DataFrame(S_trm.swapaxes(0, 1)[:, :10]).set_index(\n",
    "           pd.date_range(start = df[\"Date\"].max(), \n",
    "           end = pred_end_datei, freq = 'D').map(lambda x:\n",
    "           x if x.isoweekday() in range(1, 6) else np.nan).dropna()\n",
    "           ).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-transmission",
   "metadata": {},
   "source": [
    "## Simulación con detalles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-heating",
   "metadata": {},
   "source": [
    "### Compra Opción con parámetros aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-insurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "K = So #strike coffee base\n",
    "K2 = So_trm #strike trm base\n",
    "T = Tb / 365 #time in years\n",
    "\n",
    "#dist strike vs spot \n",
    "max_days = 15 #maximo de días que pueden pasar\n",
    "chosen_scen = random.randint(0,scen_size-1) #escenario del Movimiento Browniano simulado escogido\n",
    "days_gone = random.randint(1,max_days) # Días pasados entre t0 y momento de comprar\n",
    "\n",
    "S = S_c[chosen_scen][days_gone] #spot coffee BUY\n",
    "S2 = S_trm[chosen_scen][days_gone] #spot trm BUY\n",
    "\n",
    "\n",
    "#Combinacion de las dos primas\n",
    "primas_pct = []\n",
    "primas_pct2 = []\n",
    "primas_pct_all = []\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    #coffee\n",
    "    r = lib[i] #free risk interest rate\n",
    "    sigma = vol_coffee[i] #volatility of asset (annualized)\n",
    "    prima = call(S,K,T,r,sigma) # price of option in unites\n",
    "    prima_pct = prima / K #price of option %\n",
    "    primas_pct.append(prima_pct)\n",
    "    \n",
    "    #trm\n",
    "    r2 = ibr[i] - lib[i]\n",
    "    sigma2 = vol_trm[i]\n",
    "    prima2 = call(S2, K2, T, r2, sigma2)\n",
    "    prima_pct2 = prima2 / K2\n",
    "    primas_pct2.append(prima_pct2)\n",
    "    \n",
    "    #combinacion\n",
    "    prima_pct_all = (prima_pct + prima_pct2)\n",
    "    primas_pct_all.append(prima_pct_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "primas_pct_all_arr = np.array(primas_pct_all)\n",
    "prima_avg = primas_pct_all_arr.mean()\n",
    "print(\"Escenario Escogido\",chosen_scen)\n",
    "print(\"Días pasados entre strike y spot\",days_gone)\n",
    "print(\"Spot café\", So, \"Strike Café\", K)\n",
    "print(\"Spot TRM\", So_trm, \"Strike trm\", K2)\n",
    "print(\"Costo prima promedio cobertura\", round(prima_avg * 100,3), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(primas_pct_all, kde=True)\n",
    "plt.title(\"Costo promedio prima de cobertura\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-movie",
   "metadata": {},
   "source": [
    "Costo de capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "p995 = np.percentile(primas_pct_all_arr, 99.5)\n",
    "p90 = np.percentile(primas_pct_all_arr, 90)\n",
    "p10 = np.percentile(primas_pct_all_arr, 10)\n",
    "KdC = 0.15\n",
    "taxes = 0.7\n",
    "margen = (p995 - prima_avg)*KdC\n",
    "prima_obj = ((prima_avg + margen)/taxes)*pct_cobertura\n",
    "prima_obj_base = ((p10 + margen)/taxes)*pct_cobertura\n",
    "prima_obj_tope = ((p90 + margen)/taxes)*pct_cobertura\n",
    "\n",
    "print(\"Costo Objetivo\", round(prima_obj*100,3), \"%\")\n",
    "print(\"Costo Objetivo base\", round(prima_obj_base*100,3), \"%\")\n",
    "print(\"Costo Objetivo tope\", round(prima_obj_tope*100,3), \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-reynolds",
   "metadata": {},
   "source": [
    "### Bull Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "S = So #spot coffee base\n",
    "S2 = So_trm #spot trm base\n",
    "T = Tb / 365 #time in years\n",
    "\n",
    "#parámetros bull spread------------\n",
    "deducible = 0.05 #Strike BUY\n",
    "techo = 0.35 #Strike SELL\n",
    "#----------------------------------\n",
    "\n",
    "K = S*(1+deducible) #strike coffee BUY\n",
    "K2 = S2*(1+deducible) #strike trm BUY\n",
    "\n",
    "K_techo = S*(1+techo) #strike coffee BUY\n",
    "K2_techo  = S2*(1+techo) #strike trm SELL\n",
    "\n",
    "#Combinacion de las dos primas\n",
    "primas_coffee_b = []\n",
    "primas_coffee_s = []\n",
    "\n",
    "primas_pct = []\n",
    "primas_pct2 = []\n",
    "primas_pct_all = []\n",
    "\n",
    "for i in range(n):\n",
    "    #coffee\n",
    "    r = lib[i] #free risk interest rate\n",
    "    sigma = vol_coffee[i] #volatility of asset (annualized)\n",
    "    prima_b = call(S,K,T,r,sigma) # price of option in unites for BUY strategy\n",
    "    primas_coffee_b.append(prima_b)\n",
    "    prima_s = call(S,K_techo,T,r,sigma) # price of option in unites for SELL strategy\n",
    "    primas_coffee_s.append(prima_s)\n",
    "    prima = prima_b - prima_s\n",
    "    prima_pct = prima / K #price of option %\n",
    "    primas_pct.append(prima_pct)\n",
    "    \n",
    "    #trm\n",
    "    r2 = ibr[i] - lib[i]\n",
    "    sigma2 = vol_trm[i]\n",
    "    prima2_b = call(S2, K2, T, r2, sigma2) # price of option in unites for BUY strategy\n",
    "    prima2_s = call(S2, K2_techo, T, r2, sigma2) # price of option in unites for SELL strategy\n",
    "    prima2 = prima2_b - prima2_s \n",
    "    prima_pct2 = prima2 / K2\n",
    "    primas_pct2.append(prima_pct2)\n",
    "    \n",
    "    #combinacion\n",
    "    prima_pct_all = (prima_pct + prima_pct2)\n",
    "    primas_pct_all.append(prima_pct_all)\n",
    "    \n",
    "\n",
    "primas_pct_all_arr = np.array(primas_pct_all)\n",
    "prima_avg = primas_pct_all_arr.mean()\n",
    "\n",
    "print(\"Spot café\", So, \"Strike Café\", K, \"Techo Café\", K_techo)\n",
    "print(\"Spot TRM\", So_trm, \"Strike trm\", K2, \"Techo trm\", K2_techo)\n",
    "print(\"Costo prima promedio cobertura\", round(prima_avg * 100,3), \"%\")\n",
    "\n",
    "p995 = np.percentile(primas_pct_all_arr, 99.5)\n",
    "p90 = np.percentile(primas_pct_all_arr, 90)\n",
    "p10 = np.percentile(primas_pct_all_arr, 10)\n",
    "KdC = 0.15\n",
    "taxes = 0.7\n",
    "margen = (p995 - prima_avg)*KdC\n",
    "prima_obj = ((prima_avg + margen)/taxes)*pct_cobertura\n",
    "prima_obj_base = ((p10 + margen)/taxes)*pct_cobertura\n",
    "prima_obj_tope = ((p90 + margen)/taxes)*pct_cobertura\n",
    "\n",
    "print(\"Costo Objetivo\", round(prima_obj*100,3), \"%\")\n",
    "print(\"Costo Objetivo base\", round(prima_obj_base*100,3), \"%\")\n",
    "print(\"Costo Objetivo tope\", round(prima_obj_tope*100,3), \"%\")\n",
    "\n",
    "sns.histplot(primas_pct_all, kde=True)\n",
    "plt.title(\"Costo promedio prima de cobertura\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-teddy",
   "metadata": {},
   "source": [
    "### P&G Café"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strike Buy = K\n",
    "#Strike Sell = K_techo\n",
    "\n",
    "#1 contract = 37500 lb\n",
    "c_size = 37500\n",
    "\n",
    "#Price Buy\n",
    "primas_coffee_b_array = np.array(primas_coffee_b)\n",
    "price_b = primas_coffee_b_array.mean() # strike promedio\n",
    "price_b10 = np.percentile(primas_coffee_b_array, 10) #strike pctl 10\n",
    "price_b90 = np.percentile(primas_coffee_b_array, 90) #strike pctl 90\n",
    "\n",
    "#Price Sell\n",
    "primas_coffee_s_array = np.array(primas_coffee_s)\n",
    "price_s = primas_coffee_s_array.mean() # strike promedio\n",
    "price_s10 = np.percentile(primas_coffee_s_array, 10) #strike pctl 10\n",
    "price_s90 = np.percentile(primas_coffee_s_array, 90) #strike pctl 90\n",
    "\n",
    "\n",
    "#Spot\n",
    "df_spot_coffee = Preds_df_coffee.set_index(\"index\") # dataframe con predicciones del Movimiento Browniano\n",
    "\n",
    "#Return from call buy = IF(Spot > Strike, Spot - Strike - Price, Else, -Price)\n",
    "#Return from call sell = IF(Spot > Strike, Strike - Spot + Price, Else, +Price)\n",
    "pnl_b = []\n",
    "pnl_s = []\n",
    "pnl = []\n",
    "for spot in df_spot_coffee[0]:\n",
    "    if spot > K:\n",
    "        profit_b = spot - K - price_b\n",
    "        profit_s = K_techo - spot + price_s\n",
    "    else:\n",
    "        profit_b = - price_b\n",
    "        profit_s = price_s\n",
    "    pnl_b.append(profit_b)\n",
    "    pnl_s.append(profit_s)\n",
    "    \n",
    "    \n",
    "print(\"Strike Buy\",K ,\"Prima Buy\", price_b)\n",
    "print(\"Strike Sell\",K_techo ,\"Prima Sell\", price_s)\n",
    "\n",
    "aleatorio = random.randint(0,9)\n",
    "    \n",
    "df_pnl = df_spot_coffee[[aleatorio]]\n",
    "df_pnl[\"P&L Buy\"] = pnl_b\n",
    "df_pnl[\"P&L Sell\"] = pnl_s\n",
    "df_pnl[\"P&L\"] = df_pnl[\"P&L Buy\"] + df_pnl[\"P&L Sell\"]\n",
    "df_pnl[\"P&L USD\"] = df_pnl[\"P&L\"] /100 * 37500\n",
    "df_pnl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(df_pnl[[\"P&L\"]], label =\"P&L\")\n",
    "plt.plot(df_pnl[[ aleatorio]], label =\"Spot\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"USD C/LB\")\n",
    "plt.title(\"P&L and Spot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-postage",
   "metadata": {},
   "source": [
    "### Multiple Scenario P&L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strike Buy = K\n",
    "#Strike Sell = K_techo\n",
    "\n",
    "#Price Buy\n",
    "primas_coffee_b_array = np.array(primas_coffee_b)\n",
    "price_b = primas_coffee_b_array.mean() # strike promedio\n",
    "price_b10 = np.percentile(primas_coffee_b_array, 10) #strike pctl 10\n",
    "price_b90 = np.percentile(primas_coffee_b_array, 90) #strike pctl 90\n",
    "\n",
    "#Price Sell\n",
    "primas_coffee_s_array = np.array(primas_coffee_s)\n",
    "price_s = primas_coffee_s_array.mean() # strike promedio\n",
    "price_s10 = np.percentile(primas_coffee_s_array, 10) #strike pctl 10\n",
    "price_s90 = np.percentile(primas_coffee_s_array, 90) #strike pctl 90\n",
    "\n",
    "\n",
    "#Spot\n",
    "df_spot_coffee = Preds_df_coffee.set_index(\"index\") # dataframe con predicciones del Movimiento Browniano\n",
    "\n",
    "#Return from call buy = IF(Spot > Strike, Spot - Strike - Price, Else, -Price)\n",
    "#Return from call sell = IF(Spot > Strike, Strike - Spot + Price, Else, +Price)\n",
    "pnl_b = []\n",
    "pnl_s = []\n",
    "pnl = []\n",
    "\"\"\"for i in range(scen_size):\n",
    "    for spot in df_spot_coffee[i]:\n",
    "        if spot > K:\n",
    "            profit_b = spot - K - price_b\n",
    "            profit_s = K_techo - spot + price_s\n",
    "        else:\n",
    "            profit_b = - price_b\n",
    "            profit_s = price_s\n",
    "        pnl_b.append(profit_b)\n",
    "        pnl_s.append(profit_s)\"\"\"\n",
    "    \n",
    "    \n",
    "print(\"Strike Buy\",K ,\"Prima Buy\", price_b)\n",
    "print(\"Strike Sell\",K_techo ,\"Prima Sell\", price_s)\n",
    "\n",
    "aleatorio = random.randint(0,9)\n",
    "    \n",
    "df_pnl = df_spot_coffee[[aleatorio]]\n",
    "df_pnl[\"P&L Buy\"] = pnl_b\n",
    "df_pnl[\"P&L Sell\"] = pnl_s\n",
    "df_pnl[\"P&L\"] = df_pnl[\"P&L Buy\"] + df_pnl[\"P&L Sell\"]\n",
    "df_pnl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(df_pnl[[\"P&L\"]], label =\"P&L\")\n",
    "plt.plot(df_pnl[[ aleatorio]], label =\"Spot\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"USD C/LB\")\n",
    "plt.title(\"P&L and Spot\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
